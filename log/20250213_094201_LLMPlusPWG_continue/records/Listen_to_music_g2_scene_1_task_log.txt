From agent.py
Reset goals: The sub-goals are: 
['Turn on the dvd player.']
##############################
Goal representation from planning.py

#exp_behavior

behavior find_dvd_player_2130_around_tvstand_116(dvd_player:item):
    goal: not unknown(dvd_player)
    body:
        assert is_dvd_player(dvd_player)
        bind tvstand_instance:item where:
            is_tvstand(tvstand_instance) and id[tvstand_instance]==116
        achieve close_char(char,tvstand_instance)
        if can_open(tvstand_instance):
            achieve_once open(tvstand_instance)
            exp(dvd_player,tvstand_instance)
        else:
            exp(dvd_player,tvstand_instance)
    eff:
        unknown[dvd_player]=False
        close[dvd_player,tvstand_instance]=True
        close[tvstand_instance,dvd_player]=True
    

#exp_behavior_end

#goal_representation
 
behavior turn_on(item:item):
    body:
        achieve_once is_on(item)

behavior __goal__():
    body:
        bind dvd_player: item where:
            is_dvd_player(dvd_player) 
        # Select the DVD player
        turn_on(dvd_player)

#goal_representation_end

##############################
From agent.py->reset_goal
 
behavior turn_on(item:item):
    body:
        achieve_once is_on(item)

behavior __goal__():
    body:
        bind dvd_player: item where:
            is_dvd_player(dvd_player) 
        # Select the DVD player
        turn_on(dvd_player)

##############################
From agent.py-> find a plan in act()
walk_executor(tvstand_116)exp(dvd_player_2130, tvstand_116)walk_executor(dvd_player_2130)plugin_executor(dvd_player_2130)close_executor(dvd_player_2130)switchon_executor(dvd_player_2130)
##############################
From agent.py
walk_executor(tvstand_116)
Robot find: pillow_107, phone_71, pillow_108, drawing_111, drawing_110, Robot is close to the tvstand_116. 
##############################
From agent.py
exp(dvd_player_2130, tvstand_116)
Fail to find dvd_player_2130 around tvstand_116. 
##############################
From agent.py-> find a plan in act()
walk_executor(tvstand_273)exp(dvd_player_2130, tvstand_273)walk_executor(dvd_player_2130)plugin_executor(dvd_player_2130)close_executor(dvd_player_2130)switchon_executor(dvd_player_2130)
##############################
From agent.py
walk_executor(tvstand_273)
Robot find: drawing_288, cd_2145, headset_2131, cd_player_2129, remote_control_2124, dvd_player_2130, mat_284, Robot is close to the tvstand_273. 
##############################
From agent.py
exp(dvd_player_2130, tvstand_273)
Find dvd_player_2130. 
##############################
From agent.py-> find a plan in act()
walk_executor(dvd_player_2130)plugin_executor(dvd_player_2130)switchon_executor(dvd_player_2130)
##############################
From agent.py
walk_executor(dvd_player_2130)
Robot find: Robot is close to the tvstand_273. Robot is close to the dvd_player_2130. 
##############################
From agent.py
plugin_executor(dvd_player_2130)
Robot find: Robot is close to the tvstand_273. Robot is close to the dvd_player_2130. dvd_player_2130 is plugged in. 
##############################
From agent.py
switchon_executor(dvd_player_2130)
Robot find: Robot is close to the tvstand_273. Robot is close to the dvd_player_2130. dvd_player_2130 is turned on. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Task Summary:
Task Goal:
Turn on the dvd player.
Action History:
['walk_executor(tvstand_116)', 'walk_executor(tvstand_273)', 'walk_executor(dvd_player_2130)', 'plugin_executor(dvd_player_2130)', 'switchon_executor(dvd_player_2130)']
Time info:
Time consume: 35 seconds
Exp_helper query times: 0
Guidance query times: 0
library scale: 0
goal generate times: 1
goal correct times: 0
action_num: 5

Task complete rate:
1
Scene_id: 1
##############################
