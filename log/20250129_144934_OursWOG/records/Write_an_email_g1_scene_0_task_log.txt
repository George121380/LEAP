From agent.py
Reset goals: The sub-goals are: 
['Turn on the computer in the home office.']
##############################
Goal representation from planning.py

#exp_behavior

#exp_behavior_end

#goal_representation
 
behavior __goal__():
    body:
        bind computer: item where:
            is_computer(computer)
        # Select the computer to be turned on
        assert_hold plugged(computer)
        # Ensure the computer is plugged in
        achieve is_on(computer)
        # Ensure the computer is turned on

#goal_representation_end

##############################
From agent.py->reset_goal
 
behavior __goal__():
    body:
        bind computer: item where:
            is_computer(computer)
        # Select the computer to be turned on
        assert_hold plugged(computer)
        # Ensure the computer is plugged in
        achieve is_on(computer)
        # Ensure the computer is turned on

##############################
From agent.py-> find a plan in act()
walk_executor(computer_170)switchon_executor(computer_170)
##############################
From agent.py
walk_executor(computer_170)
Find mouse_166. Find chair_103. Find keyboard_168. Find hanger_113. Find hanger_112. Find hanger_115. Robot is inside the bedroom_67. Robot is close to the computer_170. Robot is no longer inside bathroom_1.
##############################
From agent.py
switchon_executor(computer_170)
Robot is inside the bedroom_67. Robot is close to the computer_170. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Task Summary:
Task Goal:
Turn on the computer in home office.
Action History:
['walk_executor(computer_170)', 'switchon_executor(computer_170)']
Time info:
Time consume: 15 seconds
Exp_helper query times: 0
Guidance query times: 0
library scale: 7
goal generate times: 1
goal correct times: 0

Task complete rate:
Keystate: k1 - Requires: 2 steps
Action Completion Rate: 0.0
Scene_id: 0
##############################
