From agent.py
Reset goals: The sub-goals are: 
['1. Heat the milk.  ', '2. Add cereal to the hot milk.']
##############################
Goal representation from planning.py

#exp_behavior

behavior find_towel_rack_34_around_bathroom_cabinet_40(towel_rack:item):
    goal: not unknown(towel_rack)
    body:
        assert is_towel_rack(towel_rack)
        bind bathroom_cabinet_instance:item where:
            is_bathroom_cabinet(bathroom_cabinet_instance) and id[bathroom_cabinet_instance]==40
        achieve close_char(char,bathroom_cabinet_instance)
        if can_open(bathroom_cabinet_instance):
            achieve_once open(bathroom_cabinet_instance)
            exp(towel_rack,bathroom_cabinet_instance)
        else:
            exp(towel_rack,bathroom_cabinet_instance)
    eff:
        unknown[towel_rack]=False
        close[towel_rack,bathroom_cabinet_instance]=True
        close[bathroom_cabinet_instance,towel_rack]=True
    

behavior find_milk_2043_around_fridge_289(milk:item):
    goal: not unknown(milk)
    body:
        assert is_milk(milk)
        bind fridge_instance:item where:
            is_fridge(fridge_instance) and id[fridge_instance]==289
        achieve close_char(char,fridge_instance)
        if can_open(fridge_instance):
            achieve_once open(fridge_instance)
            exp(milk,fridge_instance)
        else:
            exp(milk,fridge_instance)
    eff:
        unknown[milk]=False
        close[milk,fridge_instance]=True
        close[fridge_instance,milk]=True
    

#exp_behavior_end

#goal_representation

behavior heat_milk(milk:item, stove:item):
    body:
        achieve_once on(milk, stove)
        # Place the milk on the stove
        achieve is_on(stove)
        # Turn on the stove to heat the milk

behavior __goal__():
    body:
        bind milk: item where:
            is_milk(milk)
        # Select the milk
        bind stove: item where:
            is_stove(stove)
        # Select a stove
        heat_milk(milk, stove)
#goal_representation_end

##############################
From agent.py->reset_goal

behavior heat_milk(milk:item, stove:item):
    body:
        achieve_once on(milk, stove)
        # Place the milk on the stove
        achieve is_on(stove)
        # Turn on the stove to heat the milk

behavior __goal__():
    body:
        bind milk: item where:
            is_milk(milk)
        # Select the milk
        bind stove: item where:
            is_stove(stove)
        # Select a stove
        heat_milk(milk, stove)
##############################
From agent.py-> find a plan in act()
walk_executor(fridge_289)switchoff_executor(fridge_289)open_executor(fridge_289)exp(milk_2043, fridge_289)walk_executor(milk_2043)grab_executor(milk_2043)walk_executor(stove_2065)put_executor(milk_2043, stove_2065)switchon_executor(stove_2065)
##############################
From agent.py
walk_executor(fridge_289)
Robot find: drawing_240, drawing_239, Robot is close to the fridge_289. 
##############################
From agent.py
switchoff_executor(fridge_289)
Robot find: Robot is close to the fridge_289. fridge_289 is turned off. 
##############################
From agent.py
open_executor(fridge_289)
Robot find: sauce_2078, food_steak_2008, food_apple_2009, food_bacon_2010, food_banana_2011, food_bread_2012, food_cake_2013, food_carrot_2014, food_cereal_2015, food_cheese_2016, food_chicken_2017, food_dessert_2018, food_donut_2019, food_egg_2020, food_fish_2021, food_food_2022, food_fruit_2023, food_hamburger_2024, food_ice_cream_2025, food_jam_2026, food_kiwi_2027, food_lemon_2028, food_noodles_2029, food_oatmeal_2030, food_orange_2031, food_onion_2032, food_peanut_butter_2033, food_pizza_2034, food_potato_2035, food_rice_2036, food_salt_2037, food_snack_2038, food_sugar_2039, food_turkey_2040, food_vegetable_2041, dry_pasta_2042, milk_2043, Robot is close to the sauce_2078. Robot is close to the fridge_289. Robot is close to the food_steak_2008. Robot is close to the food_apple_2009. Robot is close to the food_bacon_2010. Robot is close to the food_banana_2011. Robot is close to the food_bread_2012. Robot is close to the food_cake_2013. Robot is close to the food_carrot_2014. Robot is close to the food_cereal_2015. Robot is close to the food_cheese_2016. Robot is close to the food_chicken_2017. Robot is close to the food_dessert_2018. Robot is close to the food_donut_2019. Robot is close to the food_egg_2020. Robot is close to the food_fish_2021. Robot is close to the food_food_2022. Robot is close to the food_fruit_2023. Robot is close to the food_hamburger_2024. Robot is close to the food_ice_cream_2025. Robot is close to the food_jam_2026. Robot is close to the food_kiwi_2027. Robot is close to the food_lemon_2028. Robot is close to the food_noodles_2029. Robot is close to the food_oatmeal_2030. Robot is close to the food_orange_2031. Robot is close to the food_onion_2032. Robot is close to the food_peanut_butter_2033. Robot is close to the food_pizza_2034. Robot is close to the food_potato_2035. Robot is close to the food_rice_2036. Robot is close to the food_salt_2037. Robot is close to the food_snack_2038. Robot is close to the food_sugar_2039. Robot is close to the food_turkey_2040. Robot is close to the food_vegetable_2041. Robot is close to the dry_pasta_2042. Robot is close to the milk_2043. fridge_289 is opened. 
##############################
From agent.py
exp(milk_2043, fridge_289)
Find milk_2043. 
##############################
From agent.py-> find a plan in act()
grab_executor(milk_2043)walk_executor(stove_2065)put_executor(milk_2043, stove_2065)switchon_executor(stove_2065)
##############################
From agent.py
grab_executor(milk_2043)
Robot find: Robot is close to the sauce_2078. Robot is close to the fridge_289. Robot is close to the food_steak_2008. Robot is close to the food_apple_2009. Robot is close to the food_bacon_2010. Robot is close to the food_banana_2011. Robot is close to the food_bread_2012. Robot is close to the food_cake_2013. Robot is close to the food_carrot_2014. Robot is close to the food_cereal_2015. Robot is close to the food_cheese_2016. Robot is close to the food_chicken_2017. Robot is close to the food_dessert_2018. Robot is close to the food_donut_2019. Robot is close to the food_egg_2020. Robot is close to the food_fish_2021. Robot is close to the food_food_2022. Robot is close to the food_fruit_2023. Robot is close to the food_hamburger_2024. Robot is close to the food_ice_cream_2025. Robot is close to the food_jam_2026. Robot is close to the food_kiwi_2027. Robot is close to the food_lemon_2028. Robot is close to the food_noodles_2029. Robot is close to the food_oatmeal_2030. Robot is close to the food_orange_2031. Robot is close to the food_onion_2032. Robot is close to the food_peanut_butter_2033. Robot is close to the food_pizza_2034. Robot is close to the food_potato_2035. Robot is close to the food_rice_2036. Robot is close to the food_salt_2037. Robot is close to the food_snack_2038. Robot is close to the food_sugar_2039. Robot is close to the food_turkey_2040. Robot is close to the food_vegetable_2041. Robot is close to the dry_pasta_2042. Robot is close to the milk_2043. Grabbing milk_2043 by right hand. 
##############################
From agent.py
walk_executor(stove_2065)
Robot find: drawing_238, drawing_241, drawing_242, drawing_243, napkin_2005, oil_2079, cup_2063, knife_2050, cup_2064, pot_2069, fryingpan_2083, Robot is close to the milk_2043. Robot is close to the stove_2065. Robot is close to the kitchen_counter_230. 
##############################
From agent.py
put_executor(milk_2043, stove_2065)
Robot find: Robot is close to the milk_2043. Robot is close to the stove_2065. Robot is close to the kitchen_counter_230. milk_2043 is close stove_2065. stove_2065 is close milk_2043. milk_2043 is on stove_2065. milk_2043 released by right hand. 
##############################
From agent.py
switchon_executor(stove_2065)
Robot find: Robot is close to the milk_2043. Robot is close to the stove_2065. Robot is close to the kitchen_counter_230. stove_2065 is turned on. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Goal representation from planning.py

#exp_behavior

behavior find_bowl_2071_around_cupboard_229(bowl:item):
    goal: not unknown(bowl)
    body:
        assert is_bowl(bowl)
        bind cupboard_instance:item where:
            is_cupboard(cupboard_instance) and id[cupboard_instance]==229
        achieve close_char(char,cupboard_instance)
        if can_open(cupboard_instance):
            achieve_once open(cupboard_instance)
            exp(bowl,cupboard_instance)
        else:
            exp(bowl,cupboard_instance)
    eff:
        unknown[bowl]=False
        close[bowl,cupboard_instance]=True
        close[cupboard_instance,bowl]=True
    

#exp_behavior_end

#goal_representation
 
behavior add_cereal_to_milk(cereal:item, milk:item):
    body:
        achieve_once inside(cereal, milk)
        # Add the cereal to the hot milk

behavior __goal__():
    body:
        bind milk: item where:
            is_milk(milk)
        # Select the hot milk

        bind cereal: item where:
            is_food_cereal(cereal)
        # Select the cereal

        add_cereal_to_milk(cereal, milk)

#goal_representation_end

##############################
Error is:
'NoneType' object is not iterable
##############################
Goal representation from planning.py

#exp_behavior

behavior find_bowl_2072_around_coffee_table_2068(bowl:item):
    goal: not unknown(bowl)
    body:
        assert is_bowl(bowl)
        bind coffee_table_instance:item where:
            is_coffee_table(coffee_table_instance) and id[coffee_table_instance]==2068
        achieve close_char(char,coffee_table_instance)
        if can_open(coffee_table_instance):
            achieve_once open(coffee_table_instance)
            exp(bowl,coffee_table_instance)
        else:
            exp(bowl,coffee_table_instance)
    eff:
        unknown[bowl]=False
        close[bowl,coffee_table_instance]=True
        close[coffee_table_instance,bowl]=True
    

#exp_behavior_end

#goal_representation
 
behavior add_cereal_to_milk(cereal:item, cup:item):
    body:
        achieve_once inside(cereal, cup)
        # Add the cereal to the cup with hot milk

behavior __goal__():
    body:
        bind cup: item where:
            is_cup(cup)
        # Select the cup with hot milk

        bind cereal: item where:
            is_food_cereal(cereal)
        # Select the cereal

        add_cereal_to_milk(cereal, cup)
        # Add the cereal to the hot milk

#goal_representation_end

##############################
From agent.py->reset_sub_goal
 
behavior add_cereal_to_milk(cereal:item, cup:item):
    body:
        achieve_once inside(cereal, cup)
        # Add the cereal to the cup with hot milk

behavior __goal__():
    body:
        bind cup: item where:
            is_cup(cup)
        # Select the cup with hot milk

        bind cereal: item where:
            is_food_cereal(cereal)
        # Select the cereal

        add_cereal_to_milk(cereal, cup)
        # Add the cereal to the hot milk

##############################
From agent.py-> find a plan in act()
walk_executor(food_cereal_2015)grab_executor(food_cereal_2015)walk_executor(cup_2063)putin_executor(food_cereal_2015, cup_2063)
##############################
From agent.py
walk_executor(food_cereal_2015)
Robot find: Robot is close to the fridge_289. Robot is close to the food_cereal_2015. 
##############################
From agent.py
grab_executor(food_cereal_2015)
Robot find: Robot is close to the fridge_289. Robot is close to the food_cereal_2015. Grabbing food_cereal_2015 by right hand. 
##############################
From agent.py
walk_executor(cup_2063)
Robot find: Robot is close to the food_cereal_2015. Robot is close to the kitchen_counter_230. Robot is close to the cup_2063. 
##############################
From agent.py
putin_executor(food_cereal_2015, cup_2063)
Robot find: Robot is close to the food_cereal_2015. Robot is close to the kitchen_counter_230. Robot is close to the cup_2063. cup_2063 is close food_cereal_2015. food_cereal_2015 is inside cup_2063. food_cereal_2015 is close cup_2063. food_cereal_2015 released by right hand. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: No
The feedback instruction: You need to put the hot milk into the cup that contains the cereal.
##############################
From agent.py
Human Instruction: You need to put the hot milk into the cup that contains the cereal.

The actions you have taken:
Action 1: Walk to fridge_289.
Action 2: Switch off fridge_289.
Action 3: Open fridge_289.
Action 4: look for milk_2043 around fridge_289.
Action 5: Grab milk_2043.
Action 6: Walk to stove_2065.
Action 7: Put milk_2043 on stove_2065.
Action 8: Switch on stove_2065.
Action 9: Walk to food_cereal_2015.
Action 10: Grab food_cereal_2015.
Action 11: Walk to cup_2063.
Action 12: Put food_cereal_2015 into cup_2063.

##############################
Goal representation from planning.py

#exp_behavior

#exp_behavior_end

#goal_representation
 
behavior add_cereal_to_milk(cereal:item, milk:item, cup:item):
    body:
        achieve_once inside(milk, cup)
        # Pour the milk into the cup that contains the cereal

behavior __goal__():
    body:
        bind cup: item where:
            is_cup(cup)
        # Select a cup that the milk is to be poured into

        bind milk: item where:
            is_milk(milk)
        # Select the milk that needs to be poured into the cup

        bind cereal: item where:
            is_food_cereal(cereal) and inside(cereal, cup)
        # Select the cereal that is already in the cup

        add_cereal_to_milk(cereal, milk, cup)

#goal_representation_end

##############################
From agent.py->reset_sub_goal
 
behavior add_cereal_to_milk(cereal:item, milk:item, cup:item):
    body:
        achieve_once inside(milk, cup)
        # Pour the milk into the cup that contains the cereal

behavior __goal__():
    body:
        bind cup: item where:
            is_cup(cup)
        # Select a cup that the milk is to be poured into

        bind milk: item where:
            is_milk(milk)
        # Select the milk that needs to be poured into the cup

        bind cereal: item where:
            is_food_cereal(cereal) and inside(cereal, cup)
        # Select the cereal that is already in the cup

        add_cereal_to_milk(cereal, milk, cup)

##############################
From agent.py-> find a plan in act()
walk_executor(milk_2043)grab_executor(milk_2043)walk_executor(cup_2063)putin_executor(milk_2043, cup_2063)
##############################
From agent.py
walk_executor(milk_2043)
Robot find: Robot is close to the stove_2065. Robot is close to the milk_2043. 
##############################
From agent.py
grab_executor(milk_2043)
Robot find: Robot is close to the stove_2065. Robot is close to the milk_2043. Grabbing milk_2043 by right hand. 
##############################
From agent.py
walk_executor(cup_2063)
Robot find: Robot is close to the milk_2043. Robot is close to the kitchen_counter_230. Robot is close to the cup_2063. 
##############################
From agent.py
putin_executor(milk_2043, cup_2063)
Robot find: Robot is close to the milk_2043. Robot is close to the kitchen_counter_230. Robot is close to the cup_2063. milk_2043 is inside cup_2063. cup_2063 is close milk_2043. milk_2043 is close cup_2063. milk_2043 released by right hand. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Task Summary:
Task Goal:
Prepare a cup of hot milk with cereal inside.
Action History:
['walk_executor(fridge_289)', 'switchoff_executor(fridge_289)', 'open_executor(fridge_289)', 'grab_executor(milk_2043)', 'walk_executor(stove_2065)', 'put_executor(milk_2043, stove_2065)', 'switchon_executor(stove_2065)', 'walk_executor(food_cereal_2015)', 'grab_executor(food_cereal_2015)', 'walk_executor(cup_2063)', 'putin_executor(food_cereal_2015, cup_2063)', 'walk_executor(milk_2043)', 'grab_executor(milk_2043)', 'walk_executor(cup_2063)', 'putin_executor(milk_2043, cup_2063)']
Time info:
Time consume: 73 seconds
Exp_helper query times: 0
Guidance query times: 0
library scale: 43
goal generate times: 4
goal correct times: 0
action_num: 15

Task complete rate:
Keystate: k1 - Requires: 8 steps
Action Completion Rate: No actions required
Scene_id: 0
##############################
