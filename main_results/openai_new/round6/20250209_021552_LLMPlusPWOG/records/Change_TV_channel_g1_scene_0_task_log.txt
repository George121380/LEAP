From agent.py
Reset goals: The sub-goals are: 
['Turn on the TV by touching the remote control.']
##############################
Goal representation from planning.py

#exp_behavior

behavior find_remote_control_2052_around_tvstand_225(remote_control:item):
    goal: not unknown(remote_control)
    body:
        assert is_remote_control(remote_control)
        bind tvstand_instance:item where:
            is_tvstand(tvstand_instance) and id[tvstand_instance]==225
        achieve close_char(char,tvstand_instance)
        if can_open(tvstand_instance):
            achieve_once open(tvstand_instance)
            exp(remote_control,tvstand_instance)
        else:
            exp(remote_control,tvstand_instance)
    eff:
        unknown[remote_control]=False
        close[remote_control,tvstand_instance]=True
        close[tvstand_instance,remote_control]=True
    

#exp_behavior_end

#goal_representation
 
behavior touch_remote(remote:item):
    body:
        touch(remote)

behavior __goal__():
    body:
        bind remote_control: item where:
            is_remote_control(remote_control)
        # Select the remote control
        touch_remote(remote_control)
        # Use the remote to turn on the TV

#goal_representation_end

##############################
From agent.py->reset_goal
 
behavior touch_remote(remote:item):
    body:
        touch(remote)

behavior __goal__():
    body:
        bind remote_control: item where:
            is_remote_control(remote_control)
        # Select the remote control
        touch_remote(remote_control)
        # Use the remote to turn on the TV

##############################
From agent.py-> find a plan in act()
walk_executor(tvstand_225)exp(remote_control_2052, tvstand_225)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(tvstand_225)
Robot find: cd_player_2060, drawing_241, drawing_242, drawing_243, cd_2075, Robot is close to the tvstand_225. 
##############################
From agent.py
exp(remote_control_2052, tvstand_225)
Fail to find remote_control_2052 around tvstand_225. 
##############################
From agent.py-> find a plan in act()
walk_executor(television_410)exp(remote_control_2052, television_410)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(television_410)
Robot find: pillow_405, mat_401, drawing_400, dvd_player_2061, pillow_406, Robot is close to the tvstand_353. Robot is close to the television_410. 
##############################
From agent.py
exp(remote_control_2052, television_410)
Fail to find remote_control_2052 around television_410. 
##############################
From agent.py-> find a plan in act()
walk_executor(bookshelf_233)open_executor(bookshelf_233)exp(remote_control_2052, bookshelf_233)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(bookshelf_233)
Robot find: Robot is close to the bookshelf_233. 
##############################
From agent.py
open_executor(bookshelf_233)
Robot find: Robot is close to the bookshelf_233. bookshelf_233 is opened. 
##############################
From agent.py
exp(remote_control_2052, bookshelf_233)
Fail to find remote_control_2052 around bookshelf_233. 
##############################
From agent.py-> find a plan in act()
walk_executor(dvd_player_2061)open_executor(dvd_player_2061)exp(remote_control_2052, dvd_player_2061)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(dvd_player_2061)
Robot find: Robot is close to the tvstand_353. Robot is close to the dvd_player_2061. 
##############################
From agent.py
open_executor(dvd_player_2061)
Robot find: Robot is close to the tvstand_353. Robot is close to the dvd_player_2061. dvd_player_2061 is opened. 
##############################
From agent.py
exp(remote_control_2052, dvd_player_2061)
Fail to find remote_control_2052 around dvd_player_2061. 
##############################
From agent.py-> find a plan in act()
walk_executor(nightstand_102)exp(remote_control_2052, nightstand_102)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(nightstand_102)
Robot find: mat_173, drawing_176, pillow_183, chair_106, pillow_182, Robot is close to the mat_173. Robot is close to the nightstand_102. 
##############################
From agent.py
exp(remote_control_2052, nightstand_102)
Fail to find remote_control_2052 around nightstand_102. 
##############################
From agent.py-> find a plan in act()
walk_executor(table_355)exp(remote_control_2052, table_355)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(table_355)
Robot find: headset_2062, spectacles_2082, remote_control_2052, clothes_jacket_2047, cat_2055, drawing_404, hairbrush_2002, vacuum_cleaner_2070, Robot is close to the couch_352. Robot is close to the mat_401. Robot is close to the table_355. 
##############################
From agent.py
exp(remote_control_2052, table_355)
Find remote_control_2052. 
##############################
From agent.py-> find a plan in act()
walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(remote_control_2052)
Robot find: Robot is close to the couch_352. Robot is close to the remote_control_2052. 
##############################
From agent.py
touch_executor(remote_control_2052)
Robot find: Robot is close to the couch_352. Robot is close to the remote_control_2052. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Task Summary:
Task Goal:
Turn on the TV by touching the remote control.
Action History:
['walk_executor(tvstand_225)', 'walk_executor(television_410)', 'walk_executor(bookshelf_233)', 'open_executor(bookshelf_233)', 'walk_executor(dvd_player_2061)', 'open_executor(dvd_player_2061)', 'walk_executor(nightstand_102)', 'walk_executor(table_355)', 'walk_executor(remote_control_2052)', 'touch_executor(remote_control_2052)']
Time info:
Time consume: 52 seconds
Exp_helper query times: 0
Guidance query times: 0
library scale: 0
goal generate times: 1
goal correct times: 0
action_num: 10

Task complete rate:
1
Scene_id: 0
##############################
