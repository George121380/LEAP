From agent.py
Reset goals: The sub-goals are: 
['1. Find the book.', '2. Put the book on the coffee table in the home office.', '3. Open the window in the home office.']
##############################
Goal representation from planning.py

#exp_behavior

behavior find_book_2067_around_bookshelf_101(book:item):
    goal: not unknown(book)
    body:
        assert is_book(book)
        bind bookshelf_instance:item where:
            is_bookshelf(bookshelf_instance) and id[bookshelf_instance]==101
        achieve close_char(char,bookshelf_instance)
        if can_open(bookshelf_instance):
            achieve_once open(bookshelf_instance)
            exp(book,bookshelf_instance)
        else:
            exp(book,bookshelf_instance)
    eff:
        unknown[book]=False
        close[book,bookshelf_instance]=True
        close[bookshelf_instance,book]=True
    

#exp_behavior_end

#goal_representation
 
def has_book():
    # Check if there is a book available in the known items
    symbol has_any_book=exists book: item : (is_book(book))
    return has_any_book

behavior __goal__():
    body:
        if has_book():
            # If there is a book in the known items, approach it
            bind book: item where:
                is_book(book)
            achieve_once inhand(book)
            # The character should hold the book once
        
        else:
            # If no book is found, search the known locations for a book
            foreach item: item:
                if is_bookshelf(item) or is_desk(item) or is_table(item):
                    # Check bookshelves, desks, and tables
                    observe(item, "Look for a book on or in this item")

#goal_representation_end

##############################
From agent.py->reset_goal
 
def has_book():
    # Check if there is a book available in the known items
    symbol has_any_book=exists book: item : (is_book(book))
    return has_any_book

behavior __goal__():
    body:
        if has_book():
            # If there is a book in the known items, approach it
            bind book: item where:
                is_book(book)
            achieve_once inhand(book)
            # The character should hold the book once
        
        else:
            # If no book is found, search the known locations for a book
            foreach item: item:
                if is_bookshelf(item) or is_desk(item) or is_table(item):
                    # Check bookshelves, desks, and tables
                    observe(item, "Look for a book on or in this item")

##############################
From agent.py-> find a plan in act()
walk_executor(bookshelf_101)open_executor(bookshelf_101)exp(book_2066, bookshelf_101)walk_executor(book_2066)grab_executor(book_2066)
##############################
From agent.py
walk_executor(bookshelf_101)
Robot find: drawing_174, drawing_176, Robot is close to the bookshelf_101. 
##############################
From agent.py
open_executor(bookshelf_101)
Robot find: Robot is close to the photoframe_185. Robot is close to the bookshelf_101. bookshelf_101 is opened. 
##############################
From agent.py
exp(book_2066, bookshelf_101)
Fail to find book_2066 around bookshelf_101. 
##############################
From agent.py-> find a plan in act()
walk_executor(bookshelf_354)open_executor(bookshelf_354)exp(book_2066, bookshelf_354)walk_executor(book_2066)grab_executor(book_2066)
##############################
From agent.py
walk_executor(bookshelf_354)
Robot find: drawing_402, drawing_403, drawing_404, book_2066, book_2067, Robot is close to the bookshelf_354. 
##############################
From agent.py
open_executor(bookshelf_354)
Robot find: Robot is close to the bookshelf_354. Robot is close to the photoframe_430. bookshelf_354 is opened. 
##############################
From agent.py
exp(book_2066, bookshelf_354)
Find book_2066. 
##############################
From agent.py-> find a plan in act()
walk_executor(book_2066)grab_executor(book_2066)
##############################
From agent.py
walk_executor(book_2066)
Robot find: Robot is close to the bookshelf_354. Robot is close to the book_2066. 
##############################
From agent.py
grab_executor(book_2066)
Robot find: Robot is close to the bookshelf_354. Robot is close to the book_2066. Grabbing book_2066 by right hand. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Goal representation from planning.py

#exp_behavior

#exp_behavior_end

#goal_representation
behavior place_book_on_table(book:item, table:item):
    body:
        achieve_once on(book, table)

behavior __goal__():
    body:
        bind book: item where:
            is_book(book) and id[book] == 2066
            # Select the book with ID 2066
        
        bind coffee_table: item where:
            is_coffee_table(coffee_table) and is_home_office(coffee_table)
            # Select a coffee table in the home office

        place_book_on_table(book, coffee_table)
        # Place the book on the coffee table in the home office
#goal_representation_end

##############################
Error is:
'NoneType' object is not iterable
##############################
Goal representation from planning.py

#exp_behavior

behavior find_coffee_filter_2000_around_coffe_maker_290(coffee_filter:item):
    goal: not unknown(coffee_filter)
    body:
        assert is_coffee_filter(coffee_filter)
        bind coffe_maker_instance:item where:
            is_coffe_maker(coffe_maker_instance) and id[coffe_maker_instance]==290
        achieve close_char(char,coffe_maker_instance)
        if can_open(coffe_maker_instance):
            achieve_once open(coffe_maker_instance)
            exp(coffee_filter,coffe_maker_instance)
        else:
            exp(coffee_filter,coffe_maker_instance)
    eff:
        unknown[coffee_filter]=False
        close[coffee_filter,coffe_maker_instance]=True
        close[coffe_maker_instance,coffee_filter]=True
    

behavior find_chair_106_around_desk_104(chair:item):
    goal: not unknown(chair)
    body:
        assert is_chair(chair)
        bind desk_instance:item where:
            is_desk(desk_instance) and id[desk_instance]==104
        achieve close_char(char,desk_instance)
        if can_open(desk_instance):
            achieve_once open(desk_instance)
            exp(chair,desk_instance)
        else:
            exp(chair,desk_instance)
    eff:
        unknown[chair]=False
        close[chair,desk_instance]=True
        close[desk_instance,chair]=True
    

#exp_behavior_end

#goal_representation
 
behavior put_book_on_table(book:item, coffee_table:item):
    body:
        achieve_once on(book, coffee_table)

behavior __goal__():
    body:
        bind book: item where:
            is_book(book) 
        # Select the book item
        
        bind coffee_table: item where:
            is_coffee_table(coffee_table)
        # Select the coffee table item

        put_book_on_table(book, coffee_table)

#goal_representation_end

##############################
From agent.py->reset_sub_goal
 
behavior put_book_on_table(book:item, coffee_table:item):
    body:
        achieve_once on(book, coffee_table)

behavior __goal__():
    body:
        bind book: item where:
            is_book(book) 
        # Select the book item
        
        bind coffee_table: item where:
            is_coffee_table(coffee_table)
        # Select the coffee table item

        put_book_on_table(book, coffee_table)

##############################
From agent.py-> find a plan in act()
walk_executor(coffee_table_2068)put_executor(book_2066, coffee_table_2068)
##############################
From agent.py
walk_executor(coffee_table_2068)
Robot find: Robot is close to the book_2066. Robot is close to the coffee_table_2068. 
##############################
From agent.py
put_executor(book_2066, coffee_table_2068)
Robot find: Robot is close to the book_2066. Robot is close to the coffee_table_2068. coffee_table_2068 is close book_2066. book_2066 is close coffee_table_2068. book_2066 is on coffee_table_2068. book_2066 released by right hand. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Goal representation from planning.py

#exp_behavior

#exp_behavior_end

#goal_representation

bind home_office: item where:
    is_home_office(home_office)

bind window: item where:
    is_window(window) and inside(window, home_office)

behavior __goal__():
    body:
        achieve open(window)

#goal_representation_end

##############################
Inner TransformationError Debug
Unexpected token Token('BIND', 'bind') at line 5658, column 1.
Expected one of: 
	* FEATURE
	* TYPEDEF
	* _PRAGMA_KEYWORD
	* INIT
	* UNDIRECTED_GENERATOR
	* BEHAVIOR
	* $END
	* OBJECTS
	* CONTROLLER
	* _NEWLINE
	* GOAL
	* IMPORT
	* INCLUDE
	* DEF
	* DOMAIN
	* GENERATOR

##############################
Goal representation after debugging in planning.py
#exp_behavior

#goal_representation

bind home_office: item where:
    is_home_office(home_office)

bind window: item where:
    is_window(window) and inside(window, home_office)

behavior __goal__():
    body:
        achieve open(window)

#goal_representation_end

##############################
Inner TransformationError Debug
Unexpected token Token('BIND', 'bind') at line 5658, column 1.
Expected one of: 
	* FEATURE
	* TYPEDEF
	* _PRAGMA_KEYWORD
	* INIT
	* UNDIRECTED_GENERATOR
	* BEHAVIOR
	* $END
	* OBJECTS
	* CONTROLLER
	* _NEWLINE
	* GOAL
	* IMPORT
	* INCLUDE
	* DEF
	* DOMAIN
	* GENERATOR

##############################
Goal representation after debugging in planning.py
#exp_behavior

#goal_representation
 
bind home_office: item where:
    is_home_office(home_office)

bind window: item where:
    is_window(window) and inside(window, home_office)

behavior __goal__():
    body:
        achieve open(window)

#goal_representation_end

##############################
Goal representation from planning.py

#exp_behavior

#exp_behavior_end

#goal_representation

behavior open_window(window:item):
    body:
        achieve_once open(window)

behavior __goal__():
    body:
        bind home_office: item where:
            is_home_office(home_office)
        bind window: item where:
            is_window(window) and inside(window, home_office)
        open_window(window)

#goal_representation_end

##############################
From agent.py->reset_sub_goal

behavior open_window(window:item):
    body:
        achieve_once open(window)

behavior __goal__():
    body:
        bind home_office: item where:
            is_home_office(home_office)
        bind window: item where:
            is_window(window) and inside(window, home_office)
        open_window(window)

##############################
From agent.py-> find a plan in act()
walk_executor(window_348)open_executor(window_348)
##############################
From agent.py
walk_executor(window_348)
Robot find: drawing_400, mat_401, pillow_405, Robot is close to the window_348. 
##############################
From agent.py
open_executor(window_348)
Robot find: Robot is close to the window_348. window_348 is opened. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Task Summary:
Task Goal:
Find a book and put it on the coffe table in home office. Then open the window in the home office.
Action History:
['walk_executor(bookshelf_101)', 'open_executor(bookshelf_101)', 'walk_executor(bookshelf_354)', 'open_executor(bookshelf_354)', 'walk_executor(book_2066)', 'grab_executor(book_2066)', 'walk_executor(coffee_table_2068)', 'put_executor(book_2066, coffee_table_2068)', 'walk_executor(window_348)', 'open_executor(window_348)']
Time info:
Time consume: 100 seconds
Exp_helper query times: 0
Guidance query times: 0
library scale: 12
goal generate times: 5
goal correct times: 0
action_num: 10

Task complete rate:
Keystate: k1 - Requires: 4 steps
Keystate: k2 - Requires: 0 steps
Action Completion Rate: No actions required
Scene_id: 0
##############################
