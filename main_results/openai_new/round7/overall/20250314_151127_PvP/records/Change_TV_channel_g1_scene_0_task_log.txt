From agent.py
Reset goals: The sub-goals are: 
['Turn on the TV by touching the remote control.']
##############################
Goal representation from planning.py

#exp_behavior

behavior find_remote_control_2052_around_tvstand_225(remote_control:item):
    goal: not unknown(remote_control)
    body:
        assert is_remote_control(remote_control)
        bind tvstand_instance:item where:
            is_tvstand(tvstand_instance) and id[tvstand_instance]==225
        achieve close_char(char,tvstand_instance)
        if can_open(tvstand_instance):
            achieve_once open(tvstand_instance)
            exp(remote_control,tvstand_instance)
        else:
            exp(remote_control,tvstand_instance)
    eff:
        unknown[remote_control]=False
        close[remote_control,tvstand_instance]=True
        close[tvstand_instance,remote_control]=True
    

#exp_behavior_end

#goal_representation
 
behavior turn_on_tv_with_remote(remote:item, tv:item):
    body:
        if not close_char(char, remote):
            walk_to(remote)
        
        if close_char(char, remote):
            touch(remote)

behavior __goal__():
    body:
        bind remote: item where:
            is_remote_control(remote)
        # Select the remote control

        bind tv: item where:
            is_television(tv)
        # Select the television

        turn_on_tv_with_remote(remote, tv)

#goal_representation_end

##############################
From agent.py->reset_goal
 
behavior turn_on_tv_with_remote(remote:item, tv:item):
    body:
        if not close_char(char, remote):
            walk_to(remote)
        
        if close_char(char, remote):
            touch(remote)

behavior __goal__():
    body:
        bind remote: item where:
            is_remote_control(remote)
        # Select the remote control

        bind tv: item where:
            is_television(tv)
        # Select the television

        turn_on_tv_with_remote(remote, tv)

##############################
From agent.py-> find a plan in act()
walk_executor(tvstand_225)exp(remote_control_2052, tvstand_225)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(tvstand_225)
Robot find: cd_player_2060, drawing_241, drawing_242, drawing_243, cd_2075, Robot is close to the tvstand_225. 
##############################
From agent.py
exp(remote_control_2052, tvstand_225)
Fail to find remote_control_2052 around tvstand_225. 
##############################
From agent.py-> find a plan in act()
walk_executor(tvstand_353)exp(remote_control_2052, tvstand_353)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(tvstand_353)
Robot find: dvd_player_2061, mat_401, drawing_400, Robot is close to the tvstand_353. 
##############################
From agent.py
exp(remote_control_2052, tvstand_353)
Fail to find remote_control_2052 around tvstand_353. 
##############################
From agent.py-> find a plan in act()
walk_executor(table_226)exp(remote_control_2052, table_226)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(table_226)
Robot find: bowl_2071, coffee_filter_2000, drawing_2003, bowl_2072, mat_236, fork_2080, drawing_238, drawing_239, drawing_240, fork_2081, mat_237, Robot is close to the table_226. 
##############################
From agent.py
exp(remote_control_2052, table_226)
Fail to find remote_control_2052 around table_226. 
##############################
From agent.py-> find a plan in act()
walk_executor(bowl_2072)exp(remote_control_2052, bowl_2072)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(bowl_2072)
Robot find: Robot is close to the table_226. Robot is close to the bowl_2072. 
##############################
From agent.py
exp(remote_control_2052, bowl_2072)
Fail to find remote_control_2052 around bowl_2072. 
##############################
From agent.py-> find a plan in act()
walk_executor(bowl_2071)exp(remote_control_2052, bowl_2071)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(bowl_2071)
Robot find: Robot is close to the table_226. Robot is close to the bowl_2071. 
##############################
From agent.py
exp(remote_control_2052, bowl_2071)
Fail to find remote_control_2052 around bowl_2071. 
##############################
From agent.py-> find a plan in act()
walk_executor(coffee_table_2068)exp(remote_control_2052, coffee_table_2068)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(coffee_table_2068)
Robot find: Robot is close to the coffee_table_2068. 
##############################
From agent.py -> query_LLM_human
Record from func query_LLM_human in agent.py
Question: Can you help me to find remote_control_2052 ?
Answer: Locate home_office_319. Once inside, find couch_352. You will find remote_control_2052 on couch_352.
Re-decompose: None

##############################
From agent.py
Human Instruction: Locate home_office_319. Once inside, find couch_352. You will find remote_control_2052 on couch_352.

The actions you have taken:
Action 1: Walk to tvstand_225.
Action 2: look for remote_control_2052 around tvstand_225.
Action 3: Walk to tvstand_353.
Action 4: look for remote_control_2052 around tvstand_353.
Action 5: Walk to table_226.
Action 6: look for remote_control_2052 around table_226.
Action 7: Walk to bowl_2072.
Action 8: look for remote_control_2052 around bowl_2072.
Action 9: Walk to bowl_2071.
Action 10: look for remote_control_2052 around bowl_2071.
Action 11: Walk to coffee_table_2068.

##############################
From agent.py
exp(remote_control_2052, coffee_table_2068)
Fail to find remote_control_2052 around coffee_table_2068. 
##############################
From agent.py-> find a plan in act()
walk_executor(couch_352)exp(remote_control_2052, couch_352)walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(couch_352)
Robot find: remote_control_2052, clothes_jacket_2047, pillow_405, cat_2055, pillow_406, hairbrush_2002, vacuum_cleaner_2070, Robot is close to the couch_352. Robot is close to the mat_401. 
##############################
From agent.py
exp(remote_control_2052, couch_352)
Find remote_control_2052. 
##############################
From agent.py-> find a plan in act()
walk_executor(remote_control_2052)touch_executor(remote_control_2052)
##############################
From agent.py
walk_executor(remote_control_2052)
Robot find: Robot is close to the couch_352. Robot is close to the remote_control_2052. 
##############################
From agent.py
touch_executor(remote_control_2052)
Robot find: Robot is close to the couch_352. Robot is close to the remote_control_2052. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Task Summary:
Task Goal:
Turn on the TV by touching the remote control.
Action History:
['walk_executor(tvstand_225)', 'walk_executor(tvstand_353)', 'walk_executor(table_226)', 'walk_executor(bowl_2072)', 'walk_executor(bowl_2071)', 'walk_executor(coffee_table_2068)', 'walk_executor(couch_352)', 'walk_executor(remote_control_2052)', 'touch_executor(remote_control_2052)']
Time info:
Time consume: 58 seconds
Exp_helper query times: 1
Guidance query times: 0
library scale: 154
goal generate times: 1
goal correct times: 0
action_num: 9

Task complete rate:
1
Scene_id: 0
##############################
