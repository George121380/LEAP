From agent.py
Reset goals: The sub-goals are: 
['1. Find a cup and pour milk into it.', '2. Heat the cup of milk using the microwave.']
##############################
Goal representation from planning.py

#exp_behavior

behavior find_cup_2049_around_kitchen_counter_123(cup:item):
    goal: not unknown(cup)
    body:
        assert is_cup(cup)
        bind kitchen_counter_instance:item where:
            is_kitchen_counter(kitchen_counter_instance) and id[kitchen_counter_instance]==123
        achieve close_char(char,kitchen_counter_instance)
        if can_open(kitchen_counter_instance):
            achieve_once open(kitchen_counter_instance)
            exp(cup,kitchen_counter_instance)
        else:
            exp(cup,kitchen_counter_instance)
    eff:
        unknown[cup]=False
        close[cup,kitchen_counter_instance]=True
        close[kitchen_counter_instance,cup]=True
    

behavior find_milk_2115_around_fridge_126(milk:item):
    goal: not unknown(milk)
    body:
        assert is_milk(milk)
        bind fridge_instance:item where:
            is_fridge(fridge_instance) and id[fridge_instance]==126
        achieve close_char(char,fridge_instance)
        if can_open(fridge_instance):
            achieve_once open(fridge_instance)
            exp(milk,fridge_instance)
        else:
            exp(milk,fridge_instance)
    eff:
        unknown[milk]=False
        close[milk,fridge_instance]=True
        close[fridge_instance,milk]=True
    

#exp_behavior_end

#goal_representation
 
behavior find_and_fill_cup_with_milk(cup: item, milk: item):
    body:
        achieve_once inside(milk, cup)

behavior __goal__():
    body:
        bind cup: item where:
            is_cup(cup)
        # Select a cup

        bind milk: item where:
            is_milk(milk)
        # Select milk

        find_and_fill_cup_with_milk(cup, milk)
        # Pour milk into the cup

#goal_representation_end

##############################
From agent.py->reset_goal
 
behavior find_and_fill_cup_with_milk(cup: item, milk: item):
    body:
        achieve_once inside(milk, cup)

behavior __goal__():
    body:
        bind cup: item where:
            is_cup(cup)
        # Select a cup

        bind milk: item where:
            is_milk(milk)
        # Select milk

        find_and_fill_cup_with_milk(cup, milk)
        # Pour milk into the cup

##############################
From agent.py-> find a plan in act()
walk_executor(kitchen_counter_123)exp(cup_2132, kitchen_counter_123)walk_executor(fridge_126)switchoff_executor(fridge_126)open_executor(fridge_126)exp(milk_2115, fridge_126)walk_executor(milk_2115)grab_executor(milk_2115)walk_executor(cup_2132)putin_executor(milk_2115, cup_2132)
##############################
From agent.py
walk_executor(kitchen_counter_123)
Robot find: tray_2068, oil_2149, knife_2035, food_kiwi_2054, food_orange_2027, Robot is close to the kitchen_counter_123. 
##############################
From agent.py
exp(cup_2132, kitchen_counter_123)
Fail to find cup_2132 around kitchen_counter_123. 
##############################
From agent.py-> find a plan in act()
walk_executor(cupboard_117)exp(cup_2132, cupboard_117)walk_executor(fridge_126)switchoff_executor(fridge_126)open_executor(fridge_126)exp(milk_2115, fridge_126)walk_executor(milk_2115)grab_executor(milk_2115)walk_executor(cup_2132)putin_executor(milk_2115, cup_2132)
##############################
From agent.py
walk_executor(cupboard_117)
Robot find: coffee_filter_2053, pot_78, Robot is close to the coffee_filter_2053. Robot is close to the cupboard_117. 
##############################
From agent.py
exp(cup_2132, cupboard_117)
Fail to find cup_2132 around cupboard_117. 
##############################
From agent.py-> find a plan in act()
walk_executor(cupboard_118)open_executor(cupboard_118)exp(cup_2132, cupboard_118)walk_executor(fridge_126)switchoff_executor(fridge_126)open_executor(fridge_126)exp(milk_2115, fridge_126)walk_executor(milk_2115)grab_executor(milk_2115)walk_executor(cup_2132)putin_executor(milk_2115, cup_2132)
##############################
From agent.py
walk_executor(cupboard_118)
Robot find: Robot is close to the cupboard_118. 
##############################
From agent.py
open_executor(cupboard_118)
Robot find: tea_2066, knife_2037, food_peanut_butter_2077, Robot is close to the tea_2066. Robot is close to the knife_2037. Robot is close to the cupboard_118. Robot is close to the food_peanut_butter_2077. cupboard_118 is opened. 
##############################
From agent.py
exp(cup_2132, cupboard_118)
Fail to find cup_2132 around cupboard_118. 
##############################
From agent.py-> find a plan in act()
walk_executor(dishwasher_129)open_executor(dishwasher_129)exp(cup_2132, dishwasher_129)walk_executor(fridge_126)switchoff_executor(fridge_126)open_executor(fridge_126)exp(milk_2115, fridge_126)walk_executor(milk_2115)grab_executor(milk_2115)walk_executor(cup_2132)putin_executor(milk_2115, cup_2132)
##############################
From agent.py
walk_executor(dishwasher_129)
Robot find: Robot is close to the dishwasher_129. 
##############################
From agent.py
open_executor(dishwasher_129)
Robot find: detergent_2011, measuring_cup_2012, Robot is close to the dishwasher_129. Robot is close to the detergent_2011. Robot is close to the measuring_cup_2012. dishwasher_129 is opened. 
##############################
From agent.py
exp(cup_2132, dishwasher_129)
Fail to find cup_2132 around dishwasher_129. 
##############################
From agent.py-> find a plan in act()
walk_executor(bookshelf_275)exp(cup_2132, bookshelf_275)walk_executor(fridge_126)switchoff_executor(fridge_126)open_executor(fridge_126)exp(milk_2115, fridge_126)walk_executor(milk_2115)grab_executor(milk_2115)walk_executor(cup_2132)putin_executor(milk_2115, cup_2132)
##############################
From agent.py
walk_executor(bookshelf_275)
Robot find: pencil_2020, Robot is close to the bookshelf_275. 
##############################
From agent.py
exp(cup_2132, bookshelf_275)
Fail to find cup_2132 around bookshelf_275. 
##############################
From agent.py-> find a plan in act()
walk_executor(microwave_135)open_executor(microwave_135)exp(cup_2132, microwave_135)walk_executor(fridge_126)switchoff_executor(fridge_126)open_executor(fridge_126)exp(milk_2115, fridge_126)walk_executor(milk_2115)grab_executor(milk_2115)walk_executor(cup_2132)putin_executor(milk_2115, cup_2132)
##############################
From agent.py
walk_executor(microwave_135)
Robot find: spectacles_2153, fryingpan_2154, Robot is close to the kitchen_counter_122. Robot is close to the microwave_135. 
##############################
From agent.py
open_executor(microwave_135)
Robot find: pot_2040, Robot is close to the pot_2040. Robot is close to the kitchen_counter_122. Robot is close to the microwave_135. microwave_135 is opened. 
##############################
From agent.py -> query_LLM_human
Record from func query_LLM_human in agent.py
Question: Can you help me to find cup_2132 ?
Answer: Go to the dining room, labeled as dining_room_41. Once there, locate table_114. Cup_2132 will be on table_114.
Re-decompose: None

##############################
From agent.py
Human Instruction: Go to the dining room, labeled as dining_room_41. Once there, locate table_114. Cup_2132 will be on table_114.

The actions you have taken:
Action 1: Walk to kitchen_counter_123.
Action 2: look for cup_2132 around kitchen_counter_123.
Action 3: Walk to cupboard_117.
Action 4: look for cup_2132 around cupboard_117.
Action 5: Walk to cupboard_118.
Action 6: Open cupboard_118.
Action 7: look for cup_2132 around cupboard_118.
Action 8: Walk to dishwasher_129.
Action 9: Open dishwasher_129.
Action 10: look for cup_2132 around dishwasher_129.
Action 11: Walk to bookshelf_275.
Action 12: look for cup_2132 around bookshelf_275.
Action 13: Walk to microwave_135.
Action 14: Open microwave_135.

##############################
From agent.py
exp(cup_2132, microwave_135)
Fail to find cup_2132 around microwave_135. 
##############################
From agent.py-> find a plan in act()
walk_executor(table_114)exp(cup_2132, table_114)walk_executor(fridge_126)switchoff_executor(fridge_126)open_executor(fridge_126)exp(milk_2115, fridge_126)walk_executor(milk_2115)grab_executor(milk_2115)walk_executor(cup_2132)putin_executor(milk_2115, cup_2132)
##############################
From agent.py
walk_executor(table_114)
Robot find: mat_102, cup_2049, pillow_103, pillow_104, pillow_105, pillow_106, lighter_2004, lighter_2039, box_2038, clothes_hat_2117, milk_2115, cup_2134, check_2058, drawing_110, drawing_111, clothes_gloves_2118, cup_2132, food_bread_2084, dry_pasta_2114, knife_2122, cup_2133, table_cloth_2005, food_food_2021, Robot is close to the table_114. Robot is close to the mat_102. 
##############################
From agent.py
exp(cup_2132, table_114)
Find cup_2132. 
##############################
From agent.py-> find a plan in act()
walk_executor(milk_2115)grab_executor(milk_2115)walk_executor(cup_2132)putin_executor(milk_2115, cup_2132)
##############################
From agent.py
walk_executor(milk_2115)
Robot find: Robot is close to the table_114. Robot is close to the milk_2115. 
##############################
From agent.py
grab_executor(milk_2115)
Robot find: Robot is close to the table_114. Robot is close to the milk_2115. Grabbing milk_2115 by right hand. 
##############################
From agent.py
walk_executor(cup_2132)
Robot find: Robot is close to the table_114. Robot is close to the milk_2115. Robot is close to the cup_2132. 
##############################
From agent.py
putin_executor(milk_2115, cup_2132)
Robot find: Robot is close to the table_114. Robot is close to the milk_2115. Robot is close to the cup_2132. milk_2115 is close cup_2132. cup_2132 is close milk_2115. milk_2115 is inside cup_2132. milk_2115 released by right hand. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Goal representation from planning.py

#exp_behavior

behavior find_dvd_player_2130_around_tvstand_116(dvd_player:item):
    goal: not unknown(dvd_player)
    body:
        assert is_dvd_player(dvd_player)
        bind tvstand_instance:item where:
            is_tvstand(tvstand_instance) and id[tvstand_instance]==116
        achieve close_char(char,tvstand_instance)
        if can_open(tvstand_instance):
            achieve_once open(tvstand_instance)
            exp(dvd_player,tvstand_instance)
        else:
            exp(dvd_player,tvstand_instance)
    eff:
        unknown[dvd_player]=False
        close[dvd_player,tvstand_instance]=True
        close[tvstand_instance,dvd_player]=True
    

#exp_behavior_end

#goal_representation
 
behavior heat_cup_of_milk_in_microwave(cup: item, microwave: item):
    body:
        achieve_once inside(cup, microwave)
        # Place the cup of milk inside the microwave
        achieve_once closed(microwave)
        # Close the microwave door
        achieve_once is_on(microwave)
        # Turn on the microwave to heat the milk

behavior __goal__():
    body:
        bind cup: item where:
            is_cup(cup) and id[cup] == 2132
        # Select cup with ID 2132 that already has milk

        bind microwave: item where:
            is_microwave(microwave)
        # Select the microwave

        heat_cup_of_milk_in_microwave(cup, microwave)
        # Heat the cup of milk in the microwave

#goal_representation_end

##############################
From agent.py->reset_sub_goal
 
behavior heat_cup_of_milk_in_microwave(cup: item, microwave: item):
    body:
        achieve_once inside(cup, microwave)
        # Place the cup of milk inside the microwave
        achieve_once closed(microwave)
        # Close the microwave door
        achieve_once is_on(microwave)
        # Turn on the microwave to heat the milk

behavior __goal__():
    body:
        bind cup: item where:
            is_cup(cup) and id[cup] == 2132
        # Select cup with ID 2132 that already has milk

        bind microwave: item where:
            is_microwave(microwave)
        # Select the microwave

        heat_cup_of_milk_in_microwave(cup, microwave)
        # Heat the cup of milk in the microwave

##############################
From agent.py-> find a plan in act()
grab_executor(cup_2132)walk_executor(microwave_135)putin_executor(cup_2132, microwave_135)close_executor(microwave_135)switchon_executor(microwave_135)
##############################
From agent.py
grab_executor(cup_2132)
Robot find: Robot is close to the table_114. Robot is close to the milk_2115. Robot is close to the cup_2132. Grabbing cup_2132 by right hand. 
##############################
From agent.py
walk_executor(microwave_135)
Robot find: Robot is close to the cup_2132. Robot is close to the pot_2040. Robot is close to the kitchen_counter_122. Robot is close to the microwave_135. 
##############################
From agent.py
putin_executor(cup_2132, microwave_135)
Robot find: Robot is close to the cup_2132. Robot is close to the pot_2040. Robot is close to the kitchen_counter_122. Robot is close to the microwave_135. cup_2132 is inside microwave_135. microwave_135 is close cup_2132. cup_2132 is close microwave_135. cup_2132 released by right hand. 
##############################
From agent.py
close_executor(microwave_135)
Robot find: Robot is close to the kitchen_counter_122. Robot is close to the microwave_135. microwave_135 is closed. 
##############################
From agent.py
switchon_executor(microwave_135)
Robot find: Robot is close to the kitchen_counter_122. Robot is close to the microwave_135. microwave_135 is turned on. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Task Summary:
Task Goal:
Get a cup of milk and heat it by microwave.
Action History:
['walk_executor(kitchen_counter_123)', 'walk_executor(cupboard_117)', 'walk_executor(cupboard_118)', 'open_executor(cupboard_118)', 'walk_executor(dishwasher_129)', 'open_executor(dishwasher_129)', 'walk_executor(bookshelf_275)', 'walk_executor(microwave_135)', 'open_executor(microwave_135)', 'walk_executor(table_114)', 'walk_executor(milk_2115)', 'grab_executor(milk_2115)', 'walk_executor(cup_2132)', 'putin_executor(milk_2115, cup_2132)', 'grab_executor(cup_2132)', 'walk_executor(microwave_135)', 'putin_executor(cup_2132, microwave_135)', 'close_executor(microwave_135)', 'switchon_executor(microwave_135)']
Time info:
Time consume: 135 seconds
Exp_helper query times: 1
Guidance query times: 0
library scale: 154
goal generate times: 2
goal correct times: 0
action_num: 19

Task complete rate:
1
Scene_id: 1
##############################
