From agent.py
Reset goals: The sub-goals are: 
['1. Locate the book in the household.', '2. Place the book on the coffee table in the home office.']
##############################
Goal representation from planning.py

#exp_behavior

behavior find_book_2066_around_bookshelf_101(book:item):
    goal: not unknown(book)
    body:
        assert is_book(book)
        bind bookshelf_instance:item where:
            is_bookshelf(bookshelf_instance) and id[bookshelf_instance]==101
        achieve close_char(char,bookshelf_instance)
        if can_open(bookshelf_instance):
            achieve_once open(bookshelf_instance)
            exp(book,bookshelf_instance)
        else:
            exp(book,bookshelf_instance)
    eff:
        unknown[book]=False
        close[book,bookshelf_instance]=True
        close[bookshelf_instance,book]=True
    

#exp_behavior_end

#goal_representation
 
behavior locate_book(book:item):
    body:
        observe(book, "Determine the current location of the book")

behavior __goal__():
    body:
        bind book: item where:
            is_book(book)
        # Select a book item

        locate_book(book)

#goal_representation_end

##############################
From agent.py->reset_goal
 
behavior locate_book(book:item):
    body:
        observe(book, "Determine the current location of the book")

behavior __goal__():
    body:
        bind book: item where:
            is_book(book)
        # Select a book item

        locate_book(book)

##############################
From agent.py-> find a plan in act()
walk_executor(bookshelf_101)open_executor(bookshelf_101)exp(book_2066, bookshelf_101)walk_executor(book_2066)open_executor(book_2066)obs(book_2066, Determine the current location of the book)
##############################
From agent.py
walk_executor(bookshelf_101)
Robot find: drawing_174, drawing_176, Robot is close to the bookshelf_101. 
##############################
From agent.py
open_executor(bookshelf_101)
Robot find: Robot is close to the photoframe_185. Robot is close to the bookshelf_101. bookshelf_101 is opened. 
##############################
From agent.py
exp(book_2066, bookshelf_101)
Fail to find book_2066 around bookshelf_101. 
##############################
From agent.py-> find a plan in act()
walk_executor(bookshelf_233)open_executor(bookshelf_233)exp(book_2066, bookshelf_233)walk_executor(book_2066)open_executor(book_2066)obs(book_2066, Determine the current location of the book)
##############################
From agent.py
walk_executor(bookshelf_233)
Robot find: Robot is close to the bookshelf_233. 
##############################
From agent.py
open_executor(bookshelf_233)
Robot find: Robot is close to the bookshelf_233. bookshelf_233 is opened. 
##############################
From agent.py
exp(book_2066, bookshelf_233)
Fail to find book_2066 around bookshelf_233. 
##############################
From agent.py-> find a plan in act()
walk_executor(bookshelf_354)open_executor(bookshelf_354)exp(book_2066, bookshelf_354)walk_executor(book_2066)open_executor(book_2066)obs(book_2066, Determine the current location of the book)
##############################
From agent.py
walk_executor(bookshelf_354)
Robot find: drawing_402, drawing_403, drawing_404, book_2066, book_2067, Robot is close to the bookshelf_354. 
##############################
From agent.py
open_executor(bookshelf_354)
Robot find: Robot is close to the bookshelf_354. Robot is close to the photoframe_430. bookshelf_354 is opened. 
##############################
From agent.py
exp(book_2066, bookshelf_354)
Find book_2066. 
##############################
From agent.py-> find a plan in act()
walk_executor(book_2066)open_executor(book_2066)obs(book_2066, Determine the current location of the book)
##############################
From agent.py
walk_executor(book_2066)
Robot find: Robot is close to the bookshelf_354. Robot is close to the book_2066. 
##############################
From agent.py
open_executor(book_2066)
Robot find: Robot is close to the bookshelf_354. Robot is close to the book_2066. book_2066 is opened. 
##############################
From agent.py
obs(book_2066, Determine the current location of the book)
Get this information:  book_2066 is close to bookshelf_354. book_2066 is close to character_65. book_2066 is on bookshelf_354. book_2066 is inside home_office_319. book_2066 is OPEN.
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Goal representation from planning.py

#exp_behavior

behavior find_oil_2079_around_walllamp_28(oil:item):
    goal: not unknown(oil)
    body:
        assert is_oil(oil)
        bind walllamp_instance:item where:
            is_walllamp(walllamp_instance) and id[walllamp_instance]==28
        achieve close_char(char,walllamp_instance)
        if can_open(walllamp_instance):
            achieve_once open(walllamp_instance)
            exp(oil,walllamp_instance)
        else:
            exp(oil,walllamp_instance)
    eff:
        unknown[oil]=False
        close[oil,walllamp_instance]=True
        close[walllamp_instance,oil]=True
    

#exp_behavior_end

#goal_representation
behavior place_book_on_coffee_table(book:item, coffee_table:item):
    body:
        achieve_once on(book, coffee_table)

behavior __goal__():
    body:
        bind book: item where:
            is_book(book)
        # Select a book item

        bind home_office: item where:
            is_home_office(home_office)
        # Select the home office

        foreach table: item:
            if is_coffee_table(table) and inside(table, home_office):
                # Identify coffee table in the home office
                place_book_on_coffee_table(book, table)
#goal_representation_end

##############################
From agent.py->reset_sub_goal
behavior place_book_on_coffee_table(book:item, coffee_table:item):
    body:
        achieve_once on(book, coffee_table)

behavior __goal__():
    body:
        bind book: item where:
            is_book(book)
        # Select a book item

        bind home_office: item where:
            is_home_office(home_office)
        # Select the home office

        foreach table: item:
            if is_coffee_table(table) and inside(table, home_office):
                # Identify coffee table in the home office
                place_book_on_coffee_table(book, table)
##############################
From agent.py-> find a plan in act()
grab_executor(book_2066)walk_executor(coffee_table_2068)put_executor(book_2066, coffee_table_2068)
##############################
From agent.py
grab_executor(book_2066)
Robot find: Robot is close to the bookshelf_354. Robot is close to the book_2066. Grabbing book_2066 by right hand. 
##############################
From agent.py
walk_executor(coffee_table_2068)
Robot find: Robot is close to the book_2066. Robot is close to the coffee_table_2068. 
##############################
From agent.py
put_executor(book_2066, coffee_table_2068)
Robot find: Robot is close to the book_2066. Robot is close to the coffee_table_2068. coffee_table_2068 is close book_2066. book_2066 is close coffee_table_2068. book_2066 is on coffee_table_2068. book_2066 released by right hand. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Task Summary:
Task Goal:
Find the book and put it on the coffee table in home office.
Action History:
['walk_executor(bookshelf_101)', 'open_executor(bookshelf_101)', 'walk_executor(bookshelf_233)', 'open_executor(bookshelf_233)', 'walk_executor(bookshelf_354)', 'open_executor(bookshelf_354)', 'walk_executor(book_2066)', 'open_executor(book_2066)', 'grab_executor(book_2066)', 'walk_executor(coffee_table_2068)', 'put_executor(book_2066, coffee_table_2068)']
Time info:
Time consume: 63 seconds
Exp_helper query times: 0
Guidance query times: 0
library scale: 83
goal generate times: 2
goal correct times: 0
action_num: 11

Task complete rate:
Keystate: k1 - Requires: 3 steps
Action Completion Rate: No actions required
Scene_id: 0
##############################
