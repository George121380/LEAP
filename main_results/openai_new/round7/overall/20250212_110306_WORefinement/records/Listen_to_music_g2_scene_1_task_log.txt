From agent.py
Reset goals: The sub-goals are: 
['Turn on the DVD player.']
##############################
Goal representation from planning.py

#exp_behavior

behavior find_dvd_player_2130_around_television_281(dvd_player:item):
    goal: not unknown(dvd_player)
    body:
        assert is_dvd_player(dvd_player)
        bind television_instance:item where:
            is_television(television_instance) and id[television_instance]==281
        achieve close_char(char,television_instance)
        if can_open(television_instance):
            achieve_once open(television_instance)
            exp(dvd_player,television_instance)
        else:
            exp(dvd_player,television_instance)
    eff:
        unknown[dvd_player]=False
        close[dvd_player,television_instance]=True
        close[television_instance,dvd_player]=True
    

#exp_behavior_end

#goal_representation
 
behavior turn_on_dvd_player(dvd_player:item):
    body:
        if has_switch(dvd_player):
            achieve is_on(dvd_player)

behavior __goal__():
    body:
        bind dvd_player: item where:
            is_dvd_player(dvd_player)
        # Select a DVD player item

        turn_on_dvd_player(dvd_player)
        # Turn on the DVD player

#goal_representation_end

##############################
From agent.py->reset_goal
 
behavior turn_on_dvd_player(dvd_player:item):
    body:
        if has_switch(dvd_player):
            achieve is_on(dvd_player)

behavior __goal__():
    body:
        bind dvd_player: item where:
            is_dvd_player(dvd_player)
        # Select a DVD player item

        turn_on_dvd_player(dvd_player)
        # Turn on the DVD player

##############################
From agent.py-> find a plan in act()
walk_executor(television_281)exp(dvd_player_2130, television_281)walk_executor(dvd_player_2130)plugin_executor(dvd_player_2130)close_executor(dvd_player_2130)switchon_executor(dvd_player_2130)
##############################
From agent.py
walk_executor(television_281)
Robot find: drawing_288, cd_2145, mat_284, headset_2131, cd_player_2129, remote_control_2124, dvd_player_2130, Robot is close to the television_281. Robot is close to the tvstand_273. 
##############################
From agent.py
exp(dvd_player_2130, television_281)
Find dvd_player_2130. 
##############################
From agent.py-> find a plan in act()
walk_executor(dvd_player_2130)plugin_executor(dvd_player_2130)switchon_executor(dvd_player_2130)
##############################
From agent.py
walk_executor(dvd_player_2130)
Robot find: Robot is close to the tvstand_273. Robot is close to the dvd_player_2130. 
##############################
From agent.py
plugin_executor(dvd_player_2130)
Robot find: Robot is close to the tvstand_273. Robot is close to the dvd_player_2130. dvd_player_2130 is plugged in. 
##############################
From agent.py
switchon_executor(dvd_player_2130)
Robot find: Robot is close to the tvstand_273. Robot is close to the dvd_player_2130. dvd_player_2130 is turned on. 
##############################
From agent.py -> evaluate_current_subgoal()
The evaluation result for current subgoal: Yes
The feedback instruction: None
##############################
Task Summary:
Task Goal:
Turn on the dvd player.
Action History:
['walk_executor(television_281)', 'walk_executor(dvd_player_2130)', 'plugin_executor(dvd_player_2130)', 'switchon_executor(dvd_player_2130)']
Time info:
Time consume: 22 seconds
Exp_helper query times: 0
Guidance query times: 0
library scale: 93
goal generate times: 1
goal correct times: 0
action_num: 4

Task complete rate:
1
Scene_id: 1
##############################
